\section{Ziele und Fragestellung}

Mit diesem Projekt verfolgen wir das Ziel, Krankheitserkennungssysteme, die auf MRI- oder Röntgenaufnahmen basieren, gegen die Auswirkungen universeller adversarial perturbations zu schützen. Unsere Fragestellung lautet: \\\\ 
\textbf{Wie können bildgebende Krankheitserkennungssysteme effektiv gegen die Bedrohungen durch universelle adversarial Perturbationen robuster gemacht werden?}

\underline{Zu den Zielen gehören:}

\begin{itemize}
  \item \textbf{Evaluierung der Robustheit bestehender Systeme:} \\Identifizieren, wie anfällig Krankheitserkennungssysteme gegenüber universeller adversarial Angriffen sind.
  \item \textbf{Entwicklung und Testen von Abwehrstrategien:} 
  \\Untersuchung verschiedener Methoden, wie Data Augmentation, adversarial Training, und Einsatz von Modellensembles zur Verbesserung der Modellrobustheit.
  \item \textbf{Analyse spezifischer und universeller Perturbationen:} \\Verstehen, welche Arten von Perturbationen besonders effektiv sind und wie sie in der Praxis identifiziert und abgewehrt werden können.
\end{itemize}


\underline{Optionale Ziele:} 
\begin{itemize}
\item \textbf{Erklärbarkeit der Modelle:} \\Untersuchung, wie die Erklärbarkeit von Modellen dazu beitragen kann, die Anfälligkeit gegenüber universellen adversarial Perturbationen zu verringern.
\item \textbf{Box-relaxation-Training:} \\
Untersuchung von Box-relaxation-Training zur Verbesserung der Modellrobustheit.
\end{itemize}