\section{Ausgangslage}
Die meisten Machine \& Deep Learning Modelle können durch einfache Veränderung der Inputwerte manipuliert werden und unerwartet oder fehlerhafte Ergebnisse erzeugen. Diese sogenannten Adversarial Attacks können dabei Schaden in unterschiedlichen Bereichen verursachen, wie bei Bilder Klassifkationen, Autonomes Fahren oder bei der Erkennung von Sprache und Texten. 

\todo{Dafür brachen wir die Fragestellung}
\begin{itemize}
    \item Mehrwert des Projektes, wieso wichtig ?
    \item Stand der Forschung ?
\end{itemize}